{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WONX_trkVaup"},"outputs":[],"source":["!pip install tape_proteins"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiPFaXDnX-Im"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgi0P8m4WjKX"},"outputs":[],"source":["import os, time\n","if not os.path.isfile(\"esmfold.model\"):\n","  # download esmfold params\n","  os.system(\"apt-get install aria2 -qq\")\n","  os.system(\"aria2c -q -x 16 https://colabfold.steineggerlab.workers.dev/esm/esmfold.model &\")\n","\n","  # install libs\n","  os.system(\"pip install -q omegaconf pytorch_lightning biopython ml_collections einops py3Dmol\")\n","  os.system(\"pip install -q git+https://github.com/NVIDIA/dllogger.git\")\n","\n","  # install openfold\n","  commit = \"6908936b68ae89f67755240e2f588c09ec31d4c8\"\n","  os.system(f\"pip install -q git+https://github.com/aqlaboratory/openfold.git@{commit}\")\n","\n","  # install esmfold\n","  os.system(f\"pip install -q git+https://github.com/sokrypton/esm.git\")\n","\n","  # wait for Params to finish downloading...\n","  if not os.path.isfile(\"esmfold.model\"):\n","    # backup source!\n","    os.system(\"aria2c -q -x 16 https://files.ipd.uw.edu/pub/esmfold/esmfold.model\")\n","  else:\n","    while os.path.isfile(\"esmfold.model.aria2\"):\n","      time.sleep(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNv7Gkg2VvsX"},"outputs":[],"source":["import os\n","import sys\n","import os.path\n","from sys import platform\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4b7Hgcv9V0XD"},"outputs":[],"source":["import sys\n","import time\n","import torch\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse\n","import requests\n","import subprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukAq5IFNV3-2"},"outputs":[],"source":["from torch import nn\n","from torch.utils import data as data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTApdVWfV4r_"},"outputs":[],"source":["from tape import datasets\n","from tape import TAPETokenizer\n","from tape import ProteinBertForMaskedLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I3UdapQMUcj1"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3BHaHASUs3B"},"outputs":[],"source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/function_predictor/code')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoxxnBbxVHnz"},"outputs":[],"source":["from Z01_ModifiedModels import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ii8IhugsVin0"},"outputs":[],"source":["from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4beXAI7WBQW"},"outputs":[],"source":["from Bio import SeqIO\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HH6yaiPPWCOo"},"outputs":[],"source":["from transformers import BertModel, BertTokenizer\n","from transformers import AlbertModel, AlbertTokenizer\n","from transformers import ElectraTokenizer, ElectraForPreTraining, ElectraForMaskedLM, ElectraModel\n","from transformers import T5EncoderModel, T5Tokenizer\n","from transformers import XLNetModel, XLNetTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_x3z3aUvWFt_"},"outputs":[],"source":["import esm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dMMu6vSWIJ1"},"outputs":[],"source":["from glob import glob\n","from Bio.Align.Applications import MafftCommandline"]},{"cell_type":"markdown","metadata":{"id":"Dwsp1AOxZtWV"},"source":["Helper Classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74qJziJnZoWu"},"outputs":[],"source":["class LoaderClass(data.Dataset):\n","    def __init__(self, input_ids, attention_mask):\n","        super().__init__()\n","        self.input_ids = input_ids\n","        self.attention_mask = attention_mask\n","    def __len__(self):\n","        return self.input_ids.shape[0]\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attention_mask[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpABP25QaBps"},"outputs":[],"source":["class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","    def forward(self, x,target = None):\n","        return (x,)"]},{"cell_type":"markdown","metadata":{"id":"RoPT0raXaRYk"},"source":["Function to generate embeddings"]},{"cell_type":"code","source":["def N03_embedding_LM(dataset_nme, model_select, data_folder, input_seqs_fasta_file, output_file_name_header, pretraining_name=None, batch_size=100, xlnet_mem_len=512):\n","    assert model_select in available_models, \"query model is not found, currently support ESM-1b, TAPE, BERT, AlBERT, Electra, T5, and Xlnet !!\"\n","    input_file = data_folder / input_seqs_fasta_file  # data path (fasta)\n","    output_file = data_folder / (output_file_name_header + model_select + \".p\")\n","\n","    # Load the model based on the selection\n","    if model_select == \"ESM_2_650\":\n","        model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n","    elif model_select == 'ESM_2_3B':\n","        model, alphabet = esm.pretrained.esm2_t36_3B_UR50D()\n","    elif model_select == 'ESM_2_15B':\n","        model, alphabet = esm.pretrained.esm2_t48_15B_UR50D()\n","    else:\n","        raise ValueError(\"Invalid model selected\")\n","\n","    batch_converter = alphabet.get_batch_converter()\n","\n","    # Read sequences from FASTA file\n","    data_set = []\n","    for seq_record in SeqIO.parse(input_file, \"fasta\"):\n","        data_set.append((str(seq_record.id), str(seq_record.seq)))\n","\n","    # Process in chunks\n","    chunk_size = 2500 if model_select == \"ESM_2_650\" else 2000\n","    data_set_list = [data_set[i:i + chunk_size] for i in range(0, len(data_set), chunk_size)]\n","\n","    # New dictionary to store embeddings with sequence names as keys\n","    seq_embeddings_dict = {}\n","    for data_set_id, one_data_set in enumerate(data_set_list):\n","        model.eval()\n","        model.cuda()\n","        for i in range(0, len(one_data_set), batch_size):\n","            print(i, \"out of\", len(one_data_set), \"; \", data_set_id, \"out of\", len(data_set_list))\n","            batch = one_data_set[i:i+batch_size] if i+batch_size <= len(one_data_set) else one_data_set[i:]\n","            batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n","            batch_tokens = batch_tokens.cuda()\n","            with torch.no_grad():\n","                # Determine the correct representation layer based on the model selected\n","                if model_select == 'ESM_2_650':\n","                    repr_layer = 33\n","                elif model_select == 'ESM_2_3B':\n","                    repr_layer = 36\n","                elif model_select == 'ESM_2_15B':\n","                    repr_layer = 48\n","                else:\n","                    raise ValueError(\"Invalid model selected\")\n","\n","                results = model(batch_tokens, repr_layers=[repr_layer])\n","            results = results[\"representations\"][repr_layer].cpu().detach()\n","\n","            # Store embeddings in the dictionary\n","            for j, (seq_id, seq) in enumerate(batch):\n","                #seq_embedding = results[j, 1: len(seq) + 1].mean(0).numpy()\n","                seq_embedding = results[j, 1: len(seq) + 1]\n","                seq_embeddings_dict[seq_id] = seq_embedding\n","\n","    # Serialize the dictionary to a file for persistent storage\n","    output_tensor_file = data_folder / (output_file_name_header + model_select + \"_embeddings_tensor.pt\")\n","    torch.save(seq_embeddings_dict, output_tensor_file)\n","\n","    print(\"Embeddings tensor dictionary saved to\", output_tensor_file)\n","    return seq_embeddings_dict"],"metadata":{"id":"q5YFlPtYRZ6F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ARA5EAdWa--D"},"source":["Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osAzf7ukbAU1"},"outputs":[],"source":["embedding_step_code = \"embedding_\"\n","dataset_names = [\"GFP\", \"PafAVariants\", \"GB1\"]\n","selected_dataset_name = dataset_names[2]\n","data_directory_path = Path(\"/content/gdrive/MyDrive/function_predictor/GB1-Dataset-FewToMore\")\n","input_fasta_filename = \"low_vs_high.fasta\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4gJQ0RdccyF"},"outputs":[],"source":["available_models = [\"ESM_2_650\", \"ESM_2_3B\", \"ESM_2_15B\"]\n","selected_model = available_models[0]\n","pretrained_model_filename = \"pretrained_\" + selected_dataset_name + \"_epoch5.pt\"\n","output_filename_prefix = \"emb_residue_level_\"+ embedding_step_code + selected_dataset_name + \"_embedding_\"\n","batch_size = 100\n","model_memory_length = 512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZNQWpHIdNmu"},"outputs":[],"source":["embeddings = N03_embedding_LM(selected_dataset_name, selected_model, data_directory_path, input_fasta_filename, output_filename_prefix, pretrained_model_filename, batch_size, model_memory_length)\n","print(\"*\" * 50)\n","print(embedding_step_code + \"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvn-nAEdwkZy"},"outputs":[],"source":["loaded_embeddings = torch.load(data_directory_path / (output_filename_prefix + selected_model + \"_embeddings_tensor.pt\"))"]},{"cell_type":"code","source":["len(embeddings)"],"metadata":{"id":"peeGknRSXmd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings.get('Sequence0').shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBvx7fpHhh6r","executionInfo":{"status":"ok","timestamp":1704121179030,"user_tz":-330,"elapsed":607,"user":{"displayName":"LMSE Computational","userId":"11856621797097047403"}},"outputId":"666c93c2-c097-427b-f3c0-d7883f7fefcc"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([265, 1280])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["embedding_tensor = loaded_embeddings.get('Sequence0')"],"metadata":{"id":"8ozV-_L5ZBTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings['Sequence0']"],"metadata":{"id":"gS92ZGx9ZFRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_tensor"],"metadata":{"id":"Y4MC8ei1bscd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_tensor.shape"],"metadata":{"id":"J5-EhCFTb2NH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rM63kV4wb7hU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}